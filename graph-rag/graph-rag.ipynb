{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62018861-a4bb-45d9-a7cd-2f9ebf0a13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bae0433-779d-4fad-ae8d-856db3d0e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"bolt://0.0.0.0:7687\"\n",
    "NEO4J_USERNAME = input(\"Your Neo4j username.\")\n",
    "NEO4J_PASSWORD = input(\"Your Neo4j password.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f37c325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/Users/m.mohammed/Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "debc7b2e-ce57-4ebf-9607-7cafbb9bd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = input(\"Your OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c149a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MISTRAL_API_KEY\"] = input(\"your MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35f83767-b9f9-4ec9-81e9-04d6d91bc59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_driver = neo4j.GraphDatabase.driver(NEO4J_URI,\n",
    "                                         auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ee8f40e-7b54-45cc-ba5c-65e3392c9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "from neo4j_graphrag.llm import MistralAILLM\n",
    "\n",
    "class Models:\n",
    "    OPEN_AI = \"OPEN_AI\"\n",
    "    MISTRAL_AI = \"MISTRAL_AI\"\n",
    "\n",
    "def get_llm(type: str = Models.MISTRAL_AI):\n",
    "    llm = None\n",
    "    if type == Models.MISTRAL_AI:\n",
    "        llm = MistralAILLM(\n",
    "            # mistral-large-latest\n",
    "            model_name=\"mistral-large-latest\",\n",
    "        )\n",
    "    else:\n",
    "        llm = OpenAILLM(\n",
    "            model_name=\"gpt-4o\",\n",
    "            model_params={\n",
    "                \"response_format\": {\"type\": \"json_object\"}, # use json_object formatting for best results\n",
    "                \"temperature\": 0 # turning temperature down for more deterministic results\n",
    "            }\n",
    "    )\n",
    "    return llm   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c2fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings\n",
    "from neo4j_graphrag.embeddings.mistral import MistralAIEmbeddings\n",
    "\n",
    "\n",
    "def get_embedder(type: str = Models.MISTRAL_AI):\n",
    "    embedder = None\n",
    "    if type == Models.MISTRAL_AI:\n",
    "        embedder = MistralAIEmbeddings()\n",
    "    else:\n",
    "        embedder = OpenAIEmbeddings()\n",
    "    return embedder   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b102be0c-4d5c-40e7-b59d-177ace03826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create text embedder\n",
    "embedder = get_embedder(type=Models.MISTRAL_AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa1c949f-e222-477b-8d84-3328a18ffe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic node labels used in your current domain (politics, etc.)\n",
    "basic_node_labels = [\n",
    "    \"Person\",\n",
    "    \"Position\",\n",
    "    \"PoliticalParty\",\n",
    "    \"Direction\",\n",
    "    \"Value\",\n",
    "    \"Goal\",\n",
    "    \"Consequence\"\n",
    "]\n",
    "\n",
    "node_labels = basic_node_labels\n",
    "\n",
    "# define relationship types\n",
    "rel_types = [\"belongs_to\", \"had_role\", \"wanted_role\", \"has_direction\", \"has_value\",\n",
    "   \"has_influence_to\", \"introduces_consequences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4a99bff-5d62-420e-9353-95298aebce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "You are a policical, financial, societal, geopolictical researcher tasks with extracting information from papers \n",
    "and structuring it in a property graph to inform further political, societal, geopolicitcal, financial and research Q&A.\n",
    "\n",
    "Extract the entities (nodes) and specify their type from the following Input text.\n",
    "Also extract the relationships between these nodes. the relationship direction goes from the start node to the end node. \n",
    "\n",
    "\n",
    "Return result as JSON using the following format:\n",
    "{{\"nodes\": [ {{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {{\"name\": \"name of entity\" }} }}],\n",
    "  \"relationships\": [{{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"details\": \"Description of the relationship\"}} }}] }}\n",
    "\n",
    "- Use only the information from the Input text. Do not add any additional information.  \n",
    "- If the input text is empty, return empty Json. \n",
    "- Make sure to create as many nodes and relationships as needed to offer rich medical context for further research.\n",
    "- An AI knowledge assistant must be able to read this graph and immediately understand the context to inform detailed research questions. \n",
    "- Multiple documents will be ingested from different sources and we are using this property graph to connect information, so make sure entity types are fairly general. \n",
    "\n",
    "Use only fhe following nodes and relationships (if provided):\n",
    "{schema}\n",
    "\n",
    "Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
    "Do respect the source and target node types for relationship and\n",
    "the relationship direction.\n",
    "\n",
    "Do not return any additional information other than the JSON in it.\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Input text:\n",
    "\n",
    "{text}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14c37b7-8600-458c-9a25-a5f8f71e5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    "\n",
    "kg_builder_pdf = SimpleKGPipeline(\n",
    "   llm=get_llm(type=Models.MISTRAL_AI),\n",
    "   driver=neo4j_driver,\n",
    "   text_splitter=FixedSizeSplitter(chunk_size=500, chunk_overlap=100),\n",
    "   embedder=embedder,\n",
    "   entities=node_labels,\n",
    "   relations=rel_types,\n",
    "   prompt_template=prompt_template,\n",
    "   from_pdf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e2a165-5adf-4d21-a361-364c2935e1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : graph-dag-1.pdf\n"
     ]
    },
    {
     "ename": "SDKError",
     "evalue": "API error occurred: Status 429\n{\"message\":\"Requests rate limit exceeded\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSDKError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m pdf_file_paths:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     pdf_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m kg_builder_pdf\u001b[38;5;241m.\u001b[39mrun_async(file_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinai\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph-rag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, path))\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/kg_builder.py:126\u001b[0m, in \u001b[0;36mSimpleKGPipeline.run_async\u001b[0;34m(self, file_path, text)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_async\u001b[39m(\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m, file_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, text: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PipelineResult:\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    Asynchronously runs the knowledge graph building process.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m        PipelineResult: The result of the pipeline execution.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mrun({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text})\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/config/runner.py:130\u001b[0m, in \u001b[0;36mPipelineRunner.run\u001b[0;34m(self, user_input)\u001b[0m\n\u001b[1;32m    126\u001b[0m     run_param \u001b[38;5;241m=\u001b[39m deep_update(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_params, user_input)\n\u001b[1;32m    127\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIPELINE_RUNNER: starting pipeline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with run_params=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprettify(run_param)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m )\n\u001b[0;32m--> 130\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mrun(data\u001b[38;5;241m=\u001b[39mrun_param)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_cleaning:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:640\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    638\u001b[0m orchestrator \u001b[38;5;241m=\u001b[39m Orchestrator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    639\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIPELINE ORCHESTRATOR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morchestrator\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 640\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m orchestrator\u001b[38;5;241m.\u001b[39mrun(data)\n\u001b[1;32m    641\u001b[0m end_time \u001b[38;5;241m=\u001b[39m default_timer()\n\u001b[1;32m    642\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIPELINE FINISHED \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morchestrator\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:327\u001b[0m, in \u001b[0;36mOrchestrator.run\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run the pipline, starting from the root nodes\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m(node without any parent). Then the callback on_task_complete\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03mwill handle the task dependencies.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_task(root, data) \u001b[38;5;28;01mfor\u001b[39;00m root \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mroots()]\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:153\u001b[0m, in \u001b[0;36mOrchestrator.run_task\u001b[0;34m(self, task, data)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_task_status(task\u001b[38;5;241m.\u001b[39mname, RunStatus\u001b[38;5;241m.\u001b[39mDONE)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_task_complete(data\u001b[38;5;241m=\u001b[39mdata, task\u001b[38;5;241m=\u001b[39mtask, result\u001b[38;5;241m=\u001b[39mres)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:192\u001b[0m, in \u001b[0;36mOrchestrator.on_task_complete\u001b[0;34m(self, data, task, result)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_result_for_component(\n\u001b[1;32m    188\u001b[0m     task\u001b[38;5;241m.\u001b[39mname, res_to_save, is_final\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mis_leaf()\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# then get the next tasks to be executed\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# and run them in //\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_task(n, data) \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext(task)])\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:153\u001b[0m, in \u001b[0;36mOrchestrator.run_task\u001b[0;34m(self, task, data)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_task_status(task\u001b[38;5;241m.\u001b[39mname, RunStatus\u001b[38;5;241m.\u001b[39mDONE)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_task_complete(data\u001b[38;5;241m=\u001b[39mdata, task\u001b[38;5;241m=\u001b[39mtask, result\u001b[38;5;241m=\u001b[39mres)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:192\u001b[0m, in \u001b[0;36mOrchestrator.on_task_complete\u001b[0;34m(self, data, task, result)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_result_for_component(\n\u001b[1;32m    188\u001b[0m     task\u001b[38;5;241m.\u001b[39mname, res_to_save, is_final\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mis_leaf()\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# then get the next tasks to be executed\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# and run them in //\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_task(n, data) \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext(task)])\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:150\u001b[0m, in \u001b[0;36mOrchestrator.run_task\u001b[0;34m(self, task, data)\u001b[0m\n\u001b[1;32m    146\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORCHESTRATOR: TASK ABORTED: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is already running or done, aborting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mrun(inputs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_task_status(task\u001b[38;5;241m.\u001b[39mname, RunStatus\u001b[38;5;241m.\u001b[39mDONE)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res:\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:105\u001b[0m, in \u001b[0;36mTaskPipelineNode.run\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    103\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTASK START \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m input=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprettify(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m start_time \u001b[38;5;241m=\u001b[39m default_timer()\n\u001b[0;32m--> 105\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    106\u001b[0m end_time \u001b[38;5;241m=\u001b[39m default_timer()\n\u001b[1;32m    107\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTASK FINISHED \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m res=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprettify(res)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:95\u001b[0m, in \u001b[0;36mTaskPipelineNode.execute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RunResult \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the task\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m        was unsuccessful.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     component_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     96\u001b[0m     run_result \u001b[38;5;241m=\u001b[39m RunResult(\n\u001b[1;32m     97\u001b[0m         result\u001b[38;5;241m=\u001b[39mcomponent_result,\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m run_result\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:33\u001b[0m, in \u001b[0;36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrapped)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m wrapper(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/embedder.py:77\u001b[0m, in \u001b[0;36mTextChunkEmbedder.run\u001b[0;34m(self, text_chunks)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@validate_call\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_chunks: TextChunks) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TextChunks:\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Embed a list of text chunks.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m        TextChunks: The input text chunks with each one having an added embedding.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TextChunks(\n\u001b[0;32m---> 77\u001b[0m         chunks\u001b[38;5;241m=\u001b[39m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunks\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     78\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/embedder.py:77\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;129m@validate_call\u001b[39m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_chunks: TextChunks) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TextChunks:\n\u001b[1;32m     68\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Embed a list of text chunks.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m        TextChunks: The input text chunks with each one having an added embedding.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TextChunks(\n\u001b[0;32m---> 77\u001b[0m         chunks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks\u001b[38;5;241m.\u001b[39mchunks]\n\u001b[1;32m     78\u001b[0m     )\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/embedder.py:56\u001b[0m, in \u001b[0;36mTextChunkEmbedder._embed_chunk\u001b[0;34m(self, text_chunk)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_embed_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_chunk: TextChunk) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TextChunk:\n\u001b[1;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Embed a single text chunk.\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        metadata containing the embeddings of the text chunk's text.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m text_chunk\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mif\u001b[39;00m text_chunk\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m     58\u001b[0m     metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/embeddings/mistral.py:59\u001b[0m, in \u001b[0;36mMistralAIEmbeddings.embed_query\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    Generate embeddings for a given query using a Mistral AI text embedding model.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m        **kwargs (Any): Additional keyword arguments to pass to the Mistral AI client.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m     embeddings_batch_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmistral_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m embeddings_batch_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m embeddings_batch_response\u001b[38;5;241m.\u001b[39mdata:\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m EmbeddingsGenerationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to retrieve embeddings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/mistralai/embeddings.py:101\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[0;34m(self, inputs, model, encoding_format, retries, server_url, timeout_ms, http_headers)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mmatch_response(http_res, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4XX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m5XX\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    100\u001b[0m     http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n\u001b[0;32m--> 101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m models\u001b[38;5;241m.\u001b[39mSDKError(\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAPI error occurred\u001b[39m\u001b[38;5;124m\"\u001b[39m, http_res\u001b[38;5;241m.\u001b[39mstatus_code, http_res_text, http_res\n\u001b[1;32m    103\u001b[0m     )\n\u001b[1;32m    105\u001b[0m content_type \u001b[38;5;241m=\u001b[39m http_res\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m http_res_text \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mstream_to_text(http_res)\n",
      "\u001b[0;31mSDKError\u001b[0m: API error occurred: Status 429\n{\"message\":\"Requests rate limit exceeded\"}"
     ]
    }
   ],
   "source": [
    "pdf_file_paths = ['graph-dag-1.pdf']\n",
    "\n",
    "for path in pdf_file_paths:\n",
    "    print(f\"Processing : {path}\")\n",
    "    pdf_result = await kg_builder_pdf.run_async(file_path=os.path.join(ROOT_DIR, \"finai\", \"graph-rag\", \"data\", path))\n",
    "    print(f\"Result: {pdf_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "857aa855-6448-4f35-b37e-5d40b4bcac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "\n",
    "create_vector_index(neo4j_driver, name=\"text_embeddings\", label=\"Chunk\",\n",
    "                   embedding_property=\"embedding\", dimensions=1536, similarity_fn=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0bcc1745-0359-4e5d-9134-2dfef9709e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "\n",
    "vector_retriever = VectorRetriever(\n",
    "   neo4j_driver,\n",
    "   index_name=\"text_embeddings\",\n",
    "   embedder=embedder,\n",
    "   return_properties=[\"text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fafdd1c-6645-40ca-89cf-6f3baebcf86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.generation import RagTemplate\n",
    "from neo4j_graphrag.generation.graphrag import GraphRAG\n",
    "\n",
    "llm = get_llm(type=Models.MISTRAL_AI)\n",
    "\n",
    "rag_template = RagTemplate(template='''Answer the Question using the following Context. Only respond with information mentioned in the Context. Do not inject any speculative information not mentioned.\n",
    "\n",
    "# Question:\n",
    "{query_text}\n",
    "\n",
    "# Context:\n",
    "{context}\n",
    "\n",
    "# Answer:\n",
    "''', expected_inputs=['query_text', 'context'])\n",
    "\n",
    "v_rag  = GraphRAG(llm=llm, retriever=vector_retriever, prompt_template=rag_template)\n",
    "# vc_rag = GraphRAG(llm=llm, retriever=vc_retriever, prompt_template=rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6c4d33cc-0acb-46a3-82e9-281bdd2a1701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Response: \n",
      "If Marine Le Pen had been elected as president in 2017, there would be potential barriers to trade, which could lead to rising borrowing costs due to wary bond investors demanding higher yields. This situation could also result in falling stock prices, particularly in companies reliant on European trade and foreign investment. The possibility of a \"Frexit\" could undermine confidence in French debt and introduce threat of volatility and market uncertainty. Additionally, such protectionist or isolationist measures could potentially lead to an economic downturn, where labor shortages and trade disruptions may cause stagnation or recession.\n",
      "\n",
      "===========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q = \"Looking at the economic outcomes of the brexit to the United Kingdom, what kind's of outcomes would we expected if Marine le Pen did managed 2017 to be elected as president and what kind of projection could we make to the french stocks at that point of time.\"\n",
    "\n",
    "print(f\"Vector Response: \\n{v_rag.search(q, retriever_config={'top_k':5}).answer}\")\n",
    "print(\"\\n===========================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-dag-venv",
   "language": "python",
   "name": "graph-dag-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
