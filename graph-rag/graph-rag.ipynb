{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62018861-a4bb-45d9-a7cd-2f9ebf0a13ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neo4j\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bae0433-779d-4fad-ae8d-856db3d0e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEO4J_URI = \"bolt://0.0.0.0:7687\"\n",
    "NEO4J_USERNAME = input(\"Your Neo4j username.\")\n",
    "NEO4J_PASSWORD = input(\"Your Neo4j password.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37c325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = \"/Users/m.mohammed/Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "debc7b2e-ce57-4ebf-9607-7cafbb9bd40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = input(\"Your OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c149a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MISTRAL_API_KEY\"] = input(\"your MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f83767-b9f9-4ec9-81e9-04d6d91bc59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_driver = neo4j.GraphDatabase.driver(NEO4J_URI,\n",
    "                                         auth=(NEO4J_USERNAME, NEO4J_PASSWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ee8f40e-7b54-45cc-ba5c-65e3392c9113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "from neo4j_graphrag.llm import MistralAILLM\n",
    "\n",
    "class Models:\n",
    "    OPEN_AI = \"OPEN_AI\"\n",
    "    MISTRAL_AI = \"MISTRAL_AI\"\n",
    "\n",
    "def get_llm(type: str = Models.MISTRAL_AI, **params):\n",
    "    llm = None\n",
    "    if type == Models.MISTRAL_AI:\n",
    "        llm = MistralAILLM(\n",
    "            # mistral-large-latest\n",
    "            model_name=\"mistral-large-latest\",\n",
    "        )\n",
    "    else:\n",
    "        model_params={\n",
    "                \"temperature\": 0 # turning temperature down for more deterministic results\n",
    "            }\n",
    "        if params.get(\"OPENAI_RESPONSE_FORMAT\") == \"json\":\n",
    "            model_params[\"response_format\"] = {\"type\": \"json_object\"}\n",
    "        \n",
    "        llm = OpenAILLM(\n",
    "            model_name=\"gpt-4o\",\n",
    "            model_params=model_params\n",
    "          \n",
    "    )\n",
    "    return llm   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68c2fb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings\n",
    "from neo4j_graphrag.embeddings.mistral import MistralAIEmbeddings\n",
    "\n",
    "\n",
    "def get_embedder(type: str = Models.MISTRAL_AI):\n",
    "    embedder = None\n",
    "    if type == Models.MISTRAL_AI:\n",
    "        embedder = MistralAIEmbeddings()\n",
    "    else:\n",
    "        embedder = OpenAIEmbeddings()\n",
    "    return embedder   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b102be0c-4d5c-40e7-b59d-177ace03826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create text embedder\n",
    "embedder = get_embedder(type=Models.OPEN_AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa1c949f-e222-477b-8d84-3328a18ffe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic node labels used in your current domain (politics, etc.)\n",
    "basic_node_labels = [\n",
    "    \"Person\",\n",
    "    \"Position\",\n",
    "    \"PoliticalParty\",\n",
    "    \"Direction\",\n",
    "    \"Value\",\n",
    "    \"Goal\",\n",
    "    \"Consequence\"\n",
    "]\n",
    "\n",
    "node_labels = basic_node_labels\n",
    "\n",
    "# define relationship types\n",
    "rel_types = [\"belongs_to\", \"had_role\", \"wanted_role\", \"has_direction\", \"has_value\",\n",
    "   \"has_influence_to\", \"introduces_consequences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4a99bff-5d62-420e-9353-95298aebce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = '''\n",
    "You are a policical, financial, societal, geopolictical researcher tasks with extracting information from papers \n",
    "and structuring it in a property graph to inform further political, societal, geopolicitcal, financial and research Q&A.\n",
    "\n",
    "Extract the entities (nodes) and specify their type from the following Input text.\n",
    "Also extract the relationships between these nodes. the relationship direction goes from the start node to the end node. \n",
    "\n",
    "\n",
    "Return result as JSON using the following format:\n",
    "{{\"nodes\": [ {{\"id\": \"0\", \"label\": \"the type of entity\", \"properties\": {{\"name\": \"name of entity\" }} }}],\n",
    "  \"relationships\": [{{\"type\": \"TYPE_OF_RELATIONSHIP\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{\"details\": \"Description of the relationship\"}} }}] }}\n",
    "\n",
    "- Use only the information from the Input text. Do not add any additional information.  \n",
    "- If the input text is empty, return empty Json. \n",
    "- Make sure to create as many nodes and relationships as needed to offer rich medical context for further research.\n",
    "- An AI knowledge assistant must be able to read this graph and immediately understand the context to inform detailed research questions. \n",
    "- Multiple documents will be ingested from different sources and we are using this property graph to connect information, so make sure entity types are fairly general. \n",
    "\n",
    "Use only fhe following nodes and relationships (if provided):\n",
    "{schema}\n",
    "\n",
    "Assign a unique ID (string) to each node, and reuse it to define relationships.\n",
    "Do respect the source and target node types for relationship and\n",
    "the relationship direction.\n",
    "\n",
    "Do not return any additional information other than the JSON in it.\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Input text:\n",
    "\n",
    "{text}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d14c37b7-8600-458c-9a25-a5f8f71e5517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    "\n",
    "kg_builder_pdf = SimpleKGPipeline(\n",
    "   llm=get_llm(type=Models.OPEN_AI, OPENAI_RESPONSE_FORMAT = \"json\"),\n",
    "   driver=neo4j_driver,\n",
    "   text_splitter=FixedSizeSplitter(chunk_size=500, chunk_overlap=100),\n",
    "   embedder=embedder,\n",
    "   entities=node_labels,\n",
    "   relations=rel_types,\n",
    "   prompt_template=prompt_template,\n",
    "   from_pdf=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31e2a165-5adf-4d21-a361-364c2935e1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : graph-dag-1.pdf\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m pdf_file_paths:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     pdf_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m kg_builder_pdf\u001b[38;5;241m.\u001b[39mrun_async(file_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinai\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph-rag\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, path))\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/kg_builder.py:126\u001b[0m, in \u001b[0;36mSimpleKGPipeline.run_async\u001b[0;34m(self, file_path, text)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_async\u001b[39m(\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m, file_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, text: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    115\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PipelineResult:\n\u001b[1;32m    116\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    Asynchronously runs the knowledge graph building process.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03m        PipelineResult: The result of the pipeline execution.\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunner\u001b[38;5;241m.\u001b[39mrun({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text})\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/config/runner.py:130\u001b[0m, in \u001b[0;36mPipelineRunner.run\u001b[0;34m(self, user_input)\u001b[0m\n\u001b[1;32m    126\u001b[0m     run_param \u001b[38;5;241m=\u001b[39m deep_update(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_params, user_input)\n\u001b[1;32m    127\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIPELINE_RUNNER: starting pipeline \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with run_params=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprettify(run_param)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    129\u001b[0m )\n\u001b[0;32m--> 130\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mrun(data\u001b[38;5;241m=\u001b[39mrun_param)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_cleaning:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:640\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    638\u001b[0m orchestrator \u001b[38;5;241m=\u001b[39m Orchestrator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    639\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIPELINE ORCHESTRATOR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morchestrator\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 640\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m orchestrator\u001b[38;5;241m.\u001b[39mrun(data)\n\u001b[1;32m    641\u001b[0m end_time \u001b[38;5;241m=\u001b[39m default_timer()\n\u001b[1;32m    642\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPIPELINE FINISHED \u001b[39m\u001b[38;5;132;01m{\u001b[39;00morchestrator\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    644\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:327\u001b[0m, in \u001b[0;36mOrchestrator.run\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run the pipline, starting from the root nodes\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;124;03m(node without any parent). Then the callback on_task_complete\u001b[39;00m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03mwill handle the task dependencies.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    326\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_task(root, data) \u001b[38;5;28;01mfor\u001b[39;00m root \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline\u001b[38;5;241m.\u001b[39mroots()]\n\u001b[0;32m--> 327\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:153\u001b[0m, in \u001b[0;36mOrchestrator.run_task\u001b[0;34m(self, task, data)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_task_status(task\u001b[38;5;241m.\u001b[39mname, RunStatus\u001b[38;5;241m.\u001b[39mDONE)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_task_complete(data\u001b[38;5;241m=\u001b[39mdata, task\u001b[38;5;241m=\u001b[39mtask, result\u001b[38;5;241m=\u001b[39mres)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:192\u001b[0m, in \u001b[0;36mOrchestrator.on_task_complete\u001b[0;34m(self, data, task, result)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_result_for_component(\n\u001b[1;32m    188\u001b[0m     task\u001b[38;5;241m.\u001b[39mname, res_to_save, is_final\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mis_leaf()\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# then get the next tasks to be executed\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# and run them in //\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_task(n, data) \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext(task)])\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:153\u001b[0m, in \u001b[0;36mOrchestrator.run_task\u001b[0;34m(self, task, data)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_task_status(task\u001b[38;5;241m.\u001b[39mname, RunStatus\u001b[38;5;241m.\u001b[39mDONE)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_task_complete(data\u001b[38;5;241m=\u001b[39mdata, task\u001b[38;5;241m=\u001b[39mtask, result\u001b[38;5;241m=\u001b[39mres)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:192\u001b[0m, in \u001b[0;36mOrchestrator.on_task_complete\u001b[0;34m(self, data, task, result)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_result_for_component(\n\u001b[1;32m    188\u001b[0m     task\u001b[38;5;241m.\u001b[39mname, res_to_save, is_final\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mis_leaf()\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# then get the next tasks to be executed\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# and run them in //\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_task(n, data) \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext(task)])\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:153\u001b[0m, in \u001b[0;36mOrchestrator.run_task\u001b[0;34m(self, task, data)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_task_status(task\u001b[38;5;241m.\u001b[39mname, RunStatus\u001b[38;5;241m.\u001b[39mDONE)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_task_complete(data\u001b[38;5;241m=\u001b[39mdata, task\u001b[38;5;241m=\u001b[39mtask, result\u001b[38;5;241m=\u001b[39mres)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:192\u001b[0m, in \u001b[0;36mOrchestrator.on_task_complete\u001b[0;34m(self, data, task, result)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_result_for_component(\n\u001b[1;32m    188\u001b[0m     task\u001b[38;5;241m.\u001b[39mname, res_to_save, is_final\u001b[38;5;241m=\u001b[39mtask\u001b[38;5;241m.\u001b[39mis_leaf()\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# then get the next tasks to be executed\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# and run them in //\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_task(n, data) \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext(task)])\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:150\u001b[0m, in \u001b[0;36mOrchestrator.run_task\u001b[0;34m(self, task, data)\u001b[0m\n\u001b[1;32m    146\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mORCHESTRATOR: TASK ABORTED: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is already running or done, aborting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m     )\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m task\u001b[38;5;241m.\u001b[39mrun(inputs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_task_status(task\u001b[38;5;241m.\u001b[39mname, RunStatus\u001b[38;5;241m.\u001b[39mDONE)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res:\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:105\u001b[0m, in \u001b[0;36mTaskPipelineNode.run\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    103\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTASK START \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m input=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprettify(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    104\u001b[0m start_time \u001b[38;5;241m=\u001b[39m default_timer()\n\u001b[0;32m--> 105\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m    106\u001b[0m end_time \u001b[38;5;241m=\u001b[39m default_timer()\n\u001b[1;32m    107\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTASK FINISHED \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m res=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprettify(res)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:95\u001b[0m, in \u001b[0;36mTaskPipelineNode.execute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RunResult \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute the task\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m        was unsuccessful.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     component_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponent\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     96\u001b[0m     run_result \u001b[38;5;241m=\u001b[39m RunResult(\n\u001b[1;32m     97\u001b[0m         result\u001b[38;5;241m=\u001b[39mcomponent_result,\n\u001b[1;32m     98\u001b[0m     )\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m run_result\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:33\u001b[0m, in \u001b[0;36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrapped)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m wrapper(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/entity_relation_extractor.py:317\u001b[0m, in \u001b[0;36mLLMEntityRelationExtractor.run\u001b[0;34m(self, chunks, document_info, lexical_graph_config, schema, examples, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m     config \u001b[38;5;241m=\u001b[39m lexical_graph_config \u001b[38;5;129;01mor\u001b[39;00m LexicalGraphConfig()\n\u001b[1;32m    316\u001b[0m     lexical_graph_builder \u001b[38;5;241m=\u001b[39m LexicalGraphBuilder(config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m--> 317\u001b[0m     lexical_graph_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m lexical_graph_builder\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m    318\u001b[0m         text_chunks\u001b[38;5;241m=\u001b[39mchunks, document_info\u001b[38;5;241m=\u001b[39mdocument_info\n\u001b[1;32m    319\u001b[0m     )\n\u001b[1;32m    320\u001b[0m     lexical_graph \u001b[38;5;241m=\u001b[39m lexical_graph_result\u001b[38;5;241m.\u001b[39mgraph\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lexical_graph_config:\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:33\u001b[0m, in \u001b[0;36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(wrapped)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper_function\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m wrapper(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/lexical_graph.py:76\u001b[0m, in \u001b[0;36mLexicalGraphBuilder.run\u001b[0;34m(self, text_chunks, document_info)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text_chunks\u001b[38;5;241m.\u001b[39mchunks) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     70\u001b[0m     tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     71\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_chunk(graph, chunk, next_chunk, document_info)\n\u001b[1;32m     72\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk, next_chunk \u001b[38;5;129;01min\u001b[39;00m zip_longest(\n\u001b[1;32m     73\u001b[0m             text_chunks\u001b[38;5;241m.\u001b[39mchunks, text_chunks\u001b[38;5;241m.\u001b[39mchunks[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m     ]\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GraphResult(\n\u001b[1;32m     78\u001b[0m     config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m     79\u001b[0m     graph\u001b[38;5;241m=\u001b[39mgraph,\n\u001b[1;32m     80\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/lexical_graph.py:82\u001b[0m, in \u001b[0;36mLexicalGraphBuilder.process_chunk\u001b[0;34m(self, graph, chunk, next_chunk, document_info)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GraphResult(\n\u001b[1;32m     78\u001b[0m         config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig,\n\u001b[1;32m     79\u001b[0m         graph\u001b[38;5;241m=\u001b[39mgraph,\n\u001b[1;32m     80\u001b[0m     )\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess_chunk\u001b[39m(\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     84\u001b[0m     graph: Neo4jGraph,\n\u001b[1;32m     85\u001b[0m     chunk: TextChunk,\n\u001b[1;32m     86\u001b[0m     next_chunk: Optional[TextChunk],\n\u001b[1;32m     87\u001b[0m     document_info: Optional[DocumentInfo] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add chunks and relationships between them (NEXT_CHUNK)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    Updates `graph` in place.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     chunk_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_chunk_node(chunk)\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pdf_file_paths = ['graph-dag-1.pdf']\n",
    "\n",
    "for path in pdf_file_paths:\n",
    "    print(f\"Processing : {path}\")\n",
    "    pdf_result = await kg_builder_pdf.run_async(file_path=os.path.join(ROOT_DIR, \"finai\", \"graph-rag\", \"data\", path))\n",
    "    print(f\"Result: {pdf_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "857aa855-6448-4f35-b37e-5d40b4bcac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "\n",
    "create_vector_index(neo4j_driver, name=\"text_embeddings\", label=\"Chunk\",\n",
    "                   embedding_property=\"embedding\", dimensions=1536, similarity_fn=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bcc1745-0359-4e5d-9134-2dfef9709e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "\n",
    "vector_retriever = VectorRetriever(\n",
    "   neo4j_driver,\n",
    "   index_name=\"text_embeddings\",\n",
    "   embedder=embedder,\n",
    "   return_properties=[\"text\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fafdd1c-6645-40ca-89cf-6f3baebcf86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j_graphrag.generation import RagTemplate\n",
    "from neo4j_graphrag.generation.graphrag import GraphRAG\n",
    "\n",
    "llm = get_llm(type=Models.OPEN_AI)\n",
    "\n",
    "rag_template = RagTemplate(template='''Answer the Question using the following Context. Only respond with information mentioned in the Context. Do not inject any speculative information not mentioned.\n",
    "\n",
    "# Question:\n",
    "{query_text}\n",
    "\n",
    "# Context:\n",
    "{context}\n",
    "\n",
    "# Answer:\n",
    "''', expected_inputs=['query_text', 'context'])\n",
    "\n",
    "v_rag  = GraphRAG(llm=llm, retriever=vector_retriever, prompt_template=rag_template)\n",
    "# vc_rag = GraphRAG(llm=llm, retriever=vc_retriever, prompt_template=rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c4d33cc-0acb-46a3-82e9-281bdd2a1701",
   "metadata": {},
   "outputs": [
    {
     "ename": "LLMGenerationError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `o1` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/llm/openai_llm.py:107\u001b[0m, in \u001b[0;36mBaseOpenAILLM.invoke\u001b[0;34m(self, input, message_history, system_instruction)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/openai/resources/chat/completions.py:859\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    858\u001b[0m validate_response_format(response_format)\n\u001b[0;32m--> 859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/openai/_base_client.py:1283\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1280\u001b[0m opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1281\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1282\u001b[0m )\n\u001b[0;32m-> 1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    958\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/openai/_base_client.py:1064\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1063\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1064\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1067\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1068\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1073\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': 'The model `o1` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLLMGenerationError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m q \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan you remember the history of our conversation?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVector Response: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mv_rag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mretriever_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m===========================\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/generation/graphrag.py:140\u001b[0m, in \u001b[0;36mGraphRAG.search\u001b[0;34m(self, query_text, message_history, examples, retriever_config, return_context)\u001b[0m\n\u001b[1;32m    138\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAG: retriever_result=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretriever_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRAG: prompt=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 140\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43msystem_instruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt_template\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msystem_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m result: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m: answer\u001b[38;5;241m.\u001b[39mcontent}\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_context:\n",
      "File \u001b[0;32m~/Downloads/graph-rag/venv/lib/python3.11/site-packages/neo4j_graphrag/llm/openai_llm.py:115\u001b[0m, in \u001b[0;36mBaseOpenAILLM.invoke\u001b[0;34m(self, input, message_history, system_instruction)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LLMResponse(content\u001b[38;5;241m=\u001b[39mcontent)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopenai\u001b[38;5;241m.\u001b[39mOpenAIError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LLMGenerationError(e)\n",
      "\u001b[0;31mLLMGenerationError\u001b[0m: Error code: 404 - {'error': {'message': 'The model `o1` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "q = \"can you remember the history of our conversation?\"\n",
    "\n",
    "print(f\"Vector Response: \\n{v_rag.search(q, retriever_config={'top_k':5}).answer}\")\n",
    "print(\"\\n===========================\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-dag-venv",
   "language": "python",
   "name": "graph-dag-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
